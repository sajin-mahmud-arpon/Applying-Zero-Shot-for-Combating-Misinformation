# Applying-Zero-Shot-for-Combating-Misinformation
Abstractâ€”The number of fake contents being spread on the
 internet platforms in rapid succession has led to the importance
 of the detection of fake news. One practical step is zero
shot classification with pre-trained language models that do
 not need further fine-tuning. In this paper, four transformer
 models DeBERTa, BART, ModernBERT, and CE-DeBERTa are
 evaluated on a smaller variant of the Kaggle Fake News dataset
 licensed under CC BY-4.0. Majority Voting and Soft Voting (with
 0.85 and 0.92 threshold) are also being used as ensemble learning
 method to enhance reliability. The top-accuracy (76.91%), and
 F1-score (72.64%), and the greatest degree of uncertainty (59.40)
 were found in DeBERTa. However, ModernBERT showed less
 performance (F1-score: 62.40%) with the lowest uncertainty
 (31.09%). DeBERTa achieved the highest score of 0.6939 based on
 the composite performance score. The highest accuracy (70.23%)
 and the highest uncertainty (31.99%) were obtained with Soft
 Voting with a threshold of 0.92 among ensemble methods.
 But Majority Voting turned out to have the strongest overall
 performance score (0.7089). In general, DeBERTa and Majority
 Voting ensemble are rather successful in terms of trustworthy
 fake news identification.
